{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_and_concat(sequences):  # sequences shape: [batch_size, len, dims...] -> ([batch_size, maxlen, dims...], [len])\n",
    "    arrays = [np.asarray(seq) for seq in sequences]\n",
    "    lengths = np.asarray([array.shape[0] for array in arrays], dtype=np.int32)\n",
    "    maxlen = np.max(lengths)\n",
    "    arrays = [np.pad(array, [(0, maxlen - array.shape[0]), (0, 0)], 'constant', constant_values=0) for array in arrays]\n",
    "    return np.asarray(arrays), lengths\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_cnf, small_lengths = pad_and_concat(\n",
    "    [[[1, -2], [2, 1]],\n",
    "     [[-2, -1], [1, -2]],\n",
    "     [[-1, -1], [-2, -2], [-1, -2]],\n",
    "      [[1, -1]],\n",
    "      [[1, -1], [1, 2]],\n",
    "      [[-2, 2]]\n",
    "     ])\n",
    "small_sol = np.asarray([1, 1, 1, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1 -2]\n",
      "  [ 2  1]\n",
      "  [ 0  0]]\n",
      "\n",
      " [[-2 -1]\n",
      "  [ 1 -2]\n",
      "  [ 0  0]]\n",
      "\n",
      " [[-1 -1]\n",
      "  [-2 -2]\n",
      "  [-1 -2]]\n",
      "\n",
      " [[ 1 -1]\n",
      "  [ 0  0]\n",
      "  [ 0  0]]\n",
      "\n",
      " [[ 1 -1]\n",
      "  [ 1  2]\n",
      "  [ 0  0]]\n",
      "\n",
      " [[-2  2]\n",
      "  [ 0  0]\n",
      "  [ 0  0]]]\n",
      "[2 2 3 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(small_cnf)\n",
    "print(small_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIABLE_NUM = 3\n",
    "EMBEDDING_SIZE = 8\n",
    "CLAUSE_SIZE = 2\n",
    "LSTM_STATE_SIZE = 8\n",
    "batch_size = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_shape(matrix, shape: list):\n",
    "    act_shape = matrix.get_shape().as_list()\n",
    "    assert act_shape == shape, \"got shape {}, expected {}\".format(act_shape, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self):\n",
    "        self.inputs = tf.placeholder(tf.int32, shape=(batch_size, None, CLAUSE_SIZE), name='inputs')\n",
    "        self.lengths = tf.placeholder(tf.int32, shape=(batch_size,), name='lengths')\n",
    "        self.labels = tf.placeholder(tf.float32, shape=(batch_size,), name='labels')\n",
    "        \n",
    "        vars_ = tf.abs(self.inputs)\n",
    "        signs = tf.cast(tf.sign(self.inputs), tf.float32)  # shape: [batch_size, None, CLAUSE_SIZE]\n",
    "\n",
    "        embeddings = tf.Variable(tf.random_uniform([VARIABLE_NUM + 1, EMBEDDING_SIZE], -1., 1), name='embeddings')\n",
    "\n",
    "        var_embeddings = tf.nn.embedding_lookup(embeddings, vars_)\n",
    "        # var_embeddings shape: [None, None, CLAUSE_SIZE, EMBEDDING_SIZE]\n",
    "        \n",
    "        clause_preembeddings = tf.concat(\n",
    "            [tf.reshape(var_embeddings, [batch_size, -1, CLAUSE_SIZE * EMBEDDING_SIZE]), \n",
    "             signs],\n",
    "            axis=2)\n",
    "        \n",
    "        PREEMBEDDING_SIZE = EMBEDDING_SIZE * CLAUSE_SIZE + CLAUSE_SIZE\n",
    "        assert_shape(clause_preembeddings, \n",
    "                     [batch_size, None, PREEMBEDDING_SIZE])\n",
    "        \n",
    "        clause_w = tf.Variable(tf.random_normal(\n",
    "            [PREEMBEDDING_SIZE, EMBEDDING_SIZE]), name='clause_w')\n",
    "        clause_b = tf.Variable(tf.random_normal([EMBEDDING_SIZE]), name='clause_b')\n",
    "        clause_embeddings = tf.reshape(tf.sigmoid(\n",
    "            tf.reshape(clause_preembeddings, [-1, PREEMBEDDING_SIZE]) @ clause_w + clause_b), \n",
    "                                       [batch_size, -1, EMBEDDING_SIZE])\n",
    "        # shape: [None, None, EMBEDDING_SIZE]\n",
    "        \n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(LSTM_STATE_SIZE)\n",
    "        hidden_state = tf.zeros([batch_size, LSTM_STATE_SIZE])\n",
    "        current_state = tf.zeros([batch_size, LSTM_STATE_SIZE])\n",
    "        state = hidden_state, current_state\n",
    "        \n",
    "        _, lstm_final_state = tf.nn.dynamic_rnn(lstm, clause_embeddings, dtype=tf.float32, \n",
    "                                               sequence_length=self.lengths\n",
    "                                               )\n",
    "        formula_embedding = lstm_final_state.h\n",
    "            \n",
    "        assert_shape(formula_embedding, [batch_size, LSTM_STATE_SIZE])\n",
    "            \n",
    "        softmax_w = tf.Variable(tf.random_normal([LSTM_STATE_SIZE, 1]), name='softmax_w')\n",
    "        softmax_b = tf.Variable(tf.random_normal([1]), name='softmax_b')\n",
    "        \n",
    "        self.logits = tf.squeeze(formula_embedding @ softmax_w, axis=1) + softmax_b\n",
    "        self.loss = tf.losses.sigmoid_cross_entropy(self.labels, self.logits) \n",
    "        self.probabilities = tf.sigmoid(self.logits)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "model = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.44, 0.46, 0.5 , 0.4 , 0.42, 0.4 ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    probs = sess.run([model.probabilities], feed_dict={\n",
    "        model.inputs: small_cnf,\n",
    "        model.lengths: small_lengths\n",
    "    })\n",
    "    \n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=0.1).minimize(model.loss)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for _ in range(100):\n",
    "        sess.run(train_op, feed_dict={\n",
    "            model.inputs: small_cnf,\n",
    "            model.labels: small_sol,\n",
    "            model.lengths: small_lengths\n",
    "        })\n",
    "    probs = sess.run(model.probabilities, feed_dict={\n",
    "        model.inputs: small_cnf,\n",
    "        model.lengths: small_lengths\n",
    "    })\n",
    "    \n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sat_array():\n",
    "    for k in range(1, 6):\n",
    "        for var_num in range(2, 5):\n",
    "            for clause_num in range(3, 10):\n",
    "                sat = {True: 0, False: 0}\n",
    "                for _ in range(100):\n",
    "                    sat[cnf.get_random_kcnf(k, var_num, clause_num).satisfiable()] += 1\n",
    "                print(k, var_num, clause_num, sat)\n",
    "# sat_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnfs = cnf.get_random_kcnfs(10000, 2, 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [cnf.satisfiable() for cnf in cnfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sat: 7510 unsat: 2490\n"
     ]
    }
   ],
   "source": [
    "print(\"sat:\", sum(1 for label in labels if label == True), \"unsat:\", sum(1 for label in labels if label == False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lists, chunk_size):\n",
    "    return [[it[i:i + chunk_size] for it in lists] for i in range(0, len(lists[0]), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 1], [10, 11]],\n",
       " [[2, 3], [12, 13]],\n",
       " [[4, 5], [14, 15]],\n",
       " [[6, 7], [16, 17]],\n",
       " [[8, 9], [18, 19]]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks([list(range(10)), list(range(10, 20))], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "skipping incomplete batch\n",
      "loss: 0.4299104 acc: 0.7691076380901691\n",
      "Epoch 1\n",
      "skipping incomplete batch\n",
      "loss: 0.40379146 acc: 0.7912164817587668\n",
      "Epoch 2\n",
      "skipping incomplete batch\n",
      "loss: 0.34892902 acc: 0.8250300076578846\n",
      "Epoch 3\n",
      "skipping incomplete batch\n",
      "loss: 0.3093779 acc: 0.8455382114251693\n",
      "Epoch 4\n",
      "skipping incomplete batch\n",
      "loss: 0.2962058 acc: 0.8506402522772729\n",
      "Epoch 5\n",
      "skipping incomplete batch\n",
      "loss: 0.29038393 acc: 0.8518407325140711\n",
      "Epoch 6\n",
      "skipping incomplete batch\n",
      "loss: 0.28698534 acc: 0.8532412927441236\n",
      "Epoch 7\n",
      "skipping incomplete batch\n",
      "loss: 0.28511658 acc: 0.8553421331339237\n",
      "Epoch 8\n",
      "skipping incomplete batch\n",
      "loss: 0.2826699 acc: 0.8561424533126591\n",
      "Epoch 9\n",
      "skipping incomplete batch\n",
      "loss: 0.2844786 acc: 0.8551420530870039\n",
      "Epoch 10\n",
      "skipping incomplete batch\n",
      "loss: 0.2780867 acc: 0.8602440940285502\n",
      "Epoch 11\n",
      "skipping incomplete batch\n",
      "loss: 0.27562436 acc: 0.8629451745054444\n",
      "Epoch 12\n",
      "skipping incomplete batch\n",
      "loss: 0.27344155 acc: 0.861944774279789\n",
      "Epoch 13\n",
      "skipping incomplete batch\n",
      "loss: 0.2733522 acc: 0.865146054967898\n",
      "Epoch 14\n",
      "skipping incomplete batch\n",
      "loss: 0.27333036 acc: 0.8645458148271382\n",
      "Epoch 15\n",
      "skipping incomplete batch\n",
      "loss: 0.27275178 acc: 0.8652460949421644\n",
      "Epoch 16\n",
      "skipping incomplete batch\n",
      "loss: 0.2715505 acc: 0.8650460149220773\n",
      "Epoch 17\n",
      "skipping incomplete batch\n",
      "loss: 0.27057272 acc: 0.8633453346082286\n",
      "Epoch 18\n",
      "skipping incomplete batch\n",
      "loss: 0.27089754 acc: 0.863945574641657\n",
      "Epoch 19\n",
      "skipping incomplete batch\n",
      "loss: 0.2679173 acc: 0.8656462549555058\n",
      "Epoch 20\n",
      "skipping incomplete batch\n",
      "loss: 0.26866505 acc: 0.8671468552134904\n",
      "Epoch 21\n",
      "skipping incomplete batch\n",
      "loss: 0.26671457 acc: 0.8659463749945808\n",
      "Epoch 22\n",
      "skipping incomplete batch\n",
      "loss: 0.26778784 acc: 0.8647458947846154\n",
      "Epoch 23\n",
      "skipping incomplete batch\n",
      "loss: 0.2647862 acc: 0.8684473754961093\n",
      "Epoch 24\n",
      "skipping incomplete batch\n",
      "loss: 0.26519132 acc: 0.8682472954134123\n",
      "Epoch 25\n",
      "skipping incomplete batch\n",
      "loss: 0.26329932 acc: 0.868947575644714\n",
      "Epoch 26\n",
      "skipping incomplete batch\n",
      "loss: 0.26781175 acc: 0.8681472554749229\n",
      "Epoch 27\n",
      "skipping incomplete batch\n",
      "loss: 0.26240048 acc: 0.8685474155598185\n",
      "Epoch 28\n",
      "skipping incomplete batch\n",
      "loss: 0.2639149 acc: 0.8691476556648011\n",
      "Epoch 29\n",
      "skipping incomplete batch\n",
      "loss: 0.26348048 acc: 0.8680472153843809\n",
      "Epoch 30\n",
      "skipping incomplete batch\n",
      "loss: 0.26449597 acc: 0.8678471353553495\n",
      "Epoch 31\n",
      "skipping incomplete batch\n",
      "loss: 0.26051477 acc: 0.8692476956480119\n",
      "Epoch 32\n",
      "skipping incomplete batch\n",
      "loss: 0.26045847 acc: 0.8701480557652367\n",
      "Epoch 33\n",
      "skipping incomplete batch\n",
      "loss: 0.2620172 acc: 0.868647455569862\n",
      "Epoch 34\n",
      "skipping incomplete batch\n",
      "loss: 0.26057798 acc: 0.8712484959830471\n",
      "Epoch 35\n",
      "skipping incomplete batch\n",
      "loss: 0.25990734 acc: 0.8716486561484411\n",
      "Epoch 36\n",
      "skipping incomplete batch\n",
      "loss: 0.26220286 acc: 0.869747895841338\n",
      "Epoch 37\n",
      "skipping incomplete batch\n",
      "loss: 0.26427874 acc: 0.8696478557597404\n",
      "Epoch 38\n",
      "skipping incomplete batch\n",
      "loss: 0.2592602 acc: 0.8722488961818696\n",
      "Epoch 39\n",
      "skipping incomplete batch\n",
      "loss: 0.2588164 acc: 0.8712484960277684\n",
      "Epoch 40\n",
      "skipping incomplete batch\n",
      "loss: 0.2573317 acc: 0.8738495365482848\n",
      "Epoch 41\n",
      "skipping incomplete batch\n",
      "loss: 0.26189658 acc: 0.8697478957787281\n",
      "Epoch 42\n",
      "skipping incomplete batch\n",
      "loss: 0.2592185 acc: 0.871248496045657\n",
      "Epoch 43\n",
      "skipping incomplete batch\n",
      "loss: 0.2568089 acc: 0.8714485760657441\n",
      "Epoch 44\n",
      "skipping incomplete batch\n",
      "loss: 0.2571855 acc: 0.8729491763505615\n",
      "Epoch 45\n",
      "skipping incomplete batch\n",
      "loss: 0.2580201 acc: 0.8730492163695494\n",
      "Epoch 46\n",
      "skipping incomplete batch\n",
      "loss: 0.25557715 acc: 0.873549416482377\n",
      "Epoch 47\n",
      "skipping incomplete batch\n",
      "loss: 0.25459877 acc: 0.8763505370229805\n",
      "Epoch 48\n",
      "skipping incomplete batch\n",
      "loss: 0.25410745 acc: 0.8729491763773943\n",
      "Epoch 49\n",
      "skipping incomplete batch\n",
      "loss: 0.25726587 acc: 0.87294917636845\n",
      "Epoch 50\n",
      "skipping incomplete batch\n",
      "loss: 0.25488356 acc: 0.875050016686696\n",
      "Epoch 51\n",
      "skipping incomplete batch\n",
      "loss: 0.258493 acc: 0.8742496965974033\n",
      "Epoch 52\n",
      "skipping incomplete batch\n",
      "loss: 0.25430626 acc: 0.8742496966242361\n",
      "Epoch 53\n",
      "skipping incomplete batch\n",
      "loss: 0.25563213 acc: 0.8733493364354571\n",
      "Epoch 54\n",
      "skipping incomplete batch\n",
      "loss: 0.25327176 acc: 0.8783513373669599\n",
      "Epoch 55\n",
      "skipping incomplete batch\n",
      "loss: 0.25463003 acc: 0.8759503769201963\n",
      "Epoch 56\n",
      "skipping incomplete batch\n",
      "loss: 0.25201556 acc: 0.8775510171792802\n",
      "Epoch 57\n",
      "skipping incomplete batch\n",
      "loss: 0.25788936 acc: 0.8765506170072904\n",
      "Epoch 58\n",
      "skipping incomplete batch\n",
      "loss: 0.2522294 acc: 0.8786514573970906\n",
      "Epoch 59\n",
      "skipping incomplete batch\n",
      "loss: 0.2503239 acc: 0.878751497371357\n",
      "Epoch 60\n",
      "skipping incomplete batch\n",
      "loss: 0.25823036 acc: 0.8766506570709997\n",
      "Epoch 61\n",
      "skipping incomplete batch\n",
      "loss: 0.25273958 acc: 0.8749499767750394\n",
      "Epoch 62\n",
      "skipping incomplete batch\n",
      "loss: 0.24916804 acc: 0.8796518575690803\n",
      "Epoch 63\n",
      "skipping incomplete batch\n",
      "loss: 0.26287988 acc: 0.8737494965382412\n",
      "Epoch 64\n",
      "skipping incomplete batch\n",
      "loss: 0.25683132 acc: 0.8721488561986589\n",
      "Epoch 65\n",
      "skipping incomplete batch\n",
      "loss: 0.24916287 acc: 0.8788515374976762\n",
      "Epoch 66\n",
      "skipping incomplete batch\n",
      "loss: 0.24885942 acc: 0.8770508170575082\n",
      "Epoch 67\n",
      "skipping incomplete batch\n",
      "loss: 0.25429896 acc: 0.8766506570083897\n",
      "Epoch 68\n",
      "skipping incomplete batch\n",
      "loss: 0.25050953 acc: 0.8770508170753968\n",
      "Epoch 69\n",
      "skipping incomplete batch\n",
      "loss: 0.25139496 acc: 0.8766506570978325\n",
      "Epoch 70\n",
      "skipping incomplete batch\n",
      "loss: 0.250255 acc: 0.8778511372809651\n",
      "Epoch 71\n",
      "skipping incomplete batch\n",
      "loss: 0.24970385 acc: 0.8784513773680592\n",
      "Epoch 72\n",
      "skipping incomplete batch\n",
      "loss: 0.25017613 acc: 0.8797518976327895\n",
      "Epoch 73\n",
      "skipping incomplete batch\n",
      "loss: 0.24995928 acc: 0.8781512572842629\n",
      "Epoch 74\n",
      "skipping incomplete batch\n",
      "loss: 0.25113878 acc: 0.8779511772552315\n",
      "Epoch 75\n",
      "skipping incomplete batch\n",
      "loss: 0.24916862 acc: 0.8785514173602142\n",
      "Epoch 76\n",
      "skipping incomplete batch\n",
      "loss: 0.24798134 acc: 0.881852737906314\n",
      "Epoch 77\n",
      "skipping incomplete batch\n",
      "loss: 0.24602607 acc: 0.8810524178796313\n",
      "Epoch 78\n",
      "skipping incomplete batch\n",
      "loss: 0.24635074 acc: 0.8795518175322039\n",
      "Epoch 79\n",
      "skipping incomplete batch\n",
      "loss: 0.24774076 acc: 0.8787514975055212\n",
      "Epoch 80\n",
      "skipping incomplete batch\n",
      "loss: 0.24825513 acc: 0.8790516174014877\n",
      "Epoch 81\n",
      "skipping incomplete batch\n",
      "loss: 0.24375758 acc: 0.8818527379778682\n",
      "Epoch 82\n",
      "skipping incomplete batch\n",
      "loss: 0.27376965 acc: 0.8661464550951663\n",
      "Epoch 83\n",
      "skipping incomplete batch\n",
      "loss: 0.2582518 acc: 0.8720488161886153\n",
      "Epoch 84\n",
      "skipping incomplete batch\n",
      "loss: 0.24794023 acc: 0.8796518575869688\n",
      "Epoch 85\n",
      "skipping incomplete batch\n",
      "loss: 0.2529977 acc: 0.8744497765459361\n",
      "Epoch 86\n",
      "skipping incomplete batch\n",
      "loss: 0.24848354 acc: 0.8796518575690803\n",
      "Epoch 87\n",
      "skipping incomplete batch\n",
      "loss: 0.25857922 acc: 0.8778511372541322\n",
      "Epoch 88\n",
      "skipping incomplete batch\n",
      "loss: 0.26278794 acc: 0.8766506570262783\n",
      "Epoch 89\n",
      "skipping incomplete batch\n",
      "loss: 0.24643703 acc: 0.8788515373992891\n",
      "Epoch 90\n",
      "skipping incomplete batch\n",
      "loss: 0.2552624 acc: 0.874949976730318\n",
      "Epoch 91\n",
      "skipping incomplete batch\n",
      "loss: 0.24543156 acc: 0.8797518976059566\n",
      "Epoch 92\n",
      "skipping incomplete batch\n",
      "loss: 0.25911266 acc: 0.8761504569134506\n",
      "Epoch 93\n",
      "skipping incomplete batch\n",
      "loss: 0.24648118 acc: 0.8822528980090981\n",
      "Epoch 94\n",
      "skipping incomplete batch\n",
      "loss: 0.24949138 acc: 0.8815526178940719\n",
      "Epoch 95\n",
      "skipping incomplete batch\n",
      "loss: 0.24595581 acc: 0.8800520176360873\n",
      "Epoch 96\n",
      "skipping incomplete batch\n",
      "loss: 0.24331777 acc: 0.8816526578683384\n",
      "Epoch 97\n",
      "skipping incomplete batch\n",
      "loss: 0.2534947 acc: 0.8779511772999529\n",
      "Epoch 98\n",
      "skipping incomplete batch\n",
      "loss: 0.2529223 acc: 0.8778511372541322\n",
      "Epoch 99\n",
      "skipping incomplete batch\n",
      "loss: 0.2453122 acc: 0.8836534582749277\n",
      "Epoch 100\n",
      "skipping incomplete batch\n",
      "loss: 0.25283903 acc: 0.877050817245338\n",
      "Epoch 101\n",
      "skipping incomplete batch\n",
      "loss: 0.24409993 acc: 0.8793517374316183\n",
      "Epoch 102\n",
      "skipping incomplete batch\n",
      "loss: 0.2504062 acc: 0.8816526579398926\n",
      "Epoch 103\n",
      "skipping incomplete batch\n",
      "loss: 0.24542922 acc: 0.8795518175411482\n",
      "Epoch 104\n",
      "skipping incomplete batch\n",
      "loss: 0.2434738 acc: 0.8832532981631993\n",
      "Epoch 105\n",
      "skipping incomplete batch\n",
      "loss: 0.27701434 acc: 0.8718487360433084\n",
      "Epoch 106\n",
      "skipping incomplete batch\n",
      "loss: 0.25414515 acc: 0.8761504569045063\n",
      "Epoch 107\n",
      "skipping incomplete batch\n",
      "loss: 0.25883543 acc: 0.8728491363136851\n",
      "Epoch 108\n",
      "skipping incomplete batch\n",
      "loss: 0.24592984 acc: 0.8786514574239234\n",
      "Epoch 109\n",
      "skipping incomplete batch\n",
      "loss: 0.2520016 acc: 0.8797518976149009\n",
      "Epoch 110\n",
      "skipping incomplete batch\n",
      "loss: 0.25293347 acc: 0.8770508170485639\n",
      "Epoch 111\n",
      "skipping incomplete batch\n",
      "loss: 0.2549622 acc: 0.876550616989402\n",
      "Epoch 112\n",
      "skipping incomplete batch\n",
      "loss: 0.25143883 acc: 0.8782512972495851\n",
      "Epoch 113\n",
      "skipping incomplete batch\n",
      "loss: 0.2671828 acc: 0.8767506970363218\n",
      "Epoch 114\n",
      "skipping incomplete batch\n",
      "loss: 0.2432446 acc: 0.8817526979231033\n",
      "Epoch 115\n",
      "skipping incomplete batch\n",
      "loss: 0.24303609 acc: 0.8848539384848931\n",
      "Epoch 116\n",
      "skipping incomplete batch\n",
      "loss: 0.2441962 acc: 0.8792516975289061\n",
      "Epoch 117\n",
      "skipping incomplete batch\n",
      "loss: 0.24414495 acc: 0.8806522577768471\n",
      "Epoch 118\n",
      "skipping incomplete batch\n",
      "loss: 0.2472809 acc: 0.8778511372183552\n",
      "Epoch 119\n",
      "skipping incomplete batch\n",
      "loss: 0.24057013 acc: 0.8830532181878336\n",
      "Epoch 120\n",
      "skipping incomplete batch\n",
      "loss: 0.24646787 acc: 0.8797518976059566\n",
      "Epoch 121\n",
      "skipping incomplete batch\n",
      "loss: 0.25693125 acc: 0.8758503368922642\n",
      "Epoch 122\n",
      "skipping incomplete batch\n",
      "loss: 0.2578828 acc: 0.8745498166364782\n",
      "Epoch 123\n",
      "skipping incomplete batch\n",
      "loss: 0.25202963 acc: 0.8811524578091763\n",
      "Epoch 124\n",
      "skipping incomplete batch\n",
      "loss: 0.24460071 acc: 0.8785514173065485\n",
      "Epoch 125\n",
      "skipping incomplete batch\n",
      "loss: 0.24726474 acc: 0.8800520176539759\n",
      "Epoch 126\n",
      "skipping incomplete batch\n",
      "loss: 0.251959 acc: 0.8789515774898311\n",
      "Epoch 127\n",
      "skipping incomplete batch\n",
      "loss: 0.24695045 acc: 0.8815526178761833\n",
      "Epoch 128\n",
      "skipping incomplete batch\n",
      "loss: 0.24482682 acc: 0.880852337823767\n",
      "Epoch 129\n",
      "skipping incomplete batch\n",
      "loss: 0.24329087 acc: 0.8861544587227906\n",
      "Epoch 130\n",
      "skipping incomplete batch\n",
      "loss: 0.24911664 acc: 0.8798519376607216\n",
      "Epoch 131\n",
      "skipping incomplete batch\n",
      "loss: 0.25196585 acc: 0.8739495765136069\n",
      "Epoch 132\n",
      "skipping incomplete batch\n",
      "loss: 0.2576088 acc: 0.874249696525849\n",
      "Epoch 133\n",
      "skipping incomplete batch\n",
      "loss: 0.24864525 acc: 0.8789515773914441\n",
      "Epoch 134\n",
      "skipping incomplete batch\n",
      "loss: 0.24255729 acc: 0.8810524177991328\n",
      "Epoch 135\n",
      "skipping incomplete batch\n",
      "loss: 0.2508408 acc: 0.878751497371357\n",
      "Epoch 136\n",
      "skipping incomplete batch\n",
      "loss: 0.24231477 acc: 0.8830532181788894\n",
      "Epoch 137\n",
      "skipping incomplete batch\n",
      "loss: 0.25234511 acc: 0.8795518176127024\n",
      "Epoch 138\n",
      "skipping incomplete batch\n",
      "loss: 0.24824335 acc: 0.87835133730435\n",
      "Epoch 139\n",
      "skipping incomplete batch\n",
      "loss: 0.25397006 acc: 0.8760504169660169\n",
      "Epoch 140\n",
      "skipping incomplete batch\n",
      "loss: 0.250424 acc: 0.8784513773233378\n",
      "Epoch 141\n",
      "skipping incomplete batch\n",
      "loss: 0.2415074 acc: 0.8841536583966997\n",
      "Epoch 142\n",
      "skipping incomplete batch\n",
      "loss: 0.24470478 acc: 0.8803521377377722\n",
      "Epoch 143\n",
      "skipping incomplete batch\n",
      "loss: 0.24696814 acc: 0.8800520176450316\n",
      "Epoch 144\n",
      "skipping incomplete batch\n",
      "loss: 0.24014731 acc: 0.8814525779019169\n",
      "Epoch 145\n",
      "skipping incomplete batch\n",
      "loss: 0.24418554 acc: 0.8817526979946575\n",
      "Epoch 146\n",
      "skipping incomplete batch\n",
      "loss: 0.24119203 acc: 0.8828531381945793\n",
      "Epoch 147\n",
      "skipping incomplete batch\n",
      "loss: 0.24321274 acc: 0.8826530580850495\n",
      "Epoch 148\n",
      "skipping incomplete batch\n",
      "loss: 0.23939952 acc: 0.8850540185675901\n",
      "Epoch 149\n",
      "skipping incomplete batch\n",
      "loss: 0.2381546 acc: 0.885354138669275\n",
      "Epoch 150\n",
      "skipping incomplete batch\n",
      "loss: 0.2366297 acc: 0.8851540586670764\n",
      "Epoch 151\n",
      "skipping incomplete batch\n",
      "loss: 0.24167727 acc: 0.8833533382805742\n",
      "Epoch 152\n",
      "skipping incomplete batch\n",
      "loss: 0.23741542 acc: 0.8862544987507227\n",
      "Epoch 153\n",
      "skipping incomplete batch\n",
      "loss: 0.2414527 acc: 0.8833533382000757\n",
      "Epoch 154\n",
      "skipping incomplete batch\n",
      "loss: 0.23978452 acc: 0.8835534182559399\n",
      "Epoch 155\n",
      "skipping incomplete batch\n",
      "loss: 0.23970854 acc: 0.8848539385027817\n",
      "Epoch 156\n",
      "skipping incomplete batch\n",
      "loss: 0.2381273 acc: 0.8879551789930173\n",
      "Epoch 157\n",
      "skipping incomplete batch\n",
      "loss: 0.250881 acc: 0.8804521777299272\n",
      "Epoch 158\n",
      "skipping incomplete batch\n",
      "loss: 0.23951416 acc: 0.8865546188524076\n",
      "Epoch 159\n",
      "skipping incomplete batch\n",
      "loss: 0.2375592 acc: 0.8858543387463256\n",
      "Epoch 160\n",
      "skipping incomplete batch\n",
      "loss: 0.2481811 acc: 0.8808523377253801\n",
      "Epoch 161\n",
      "skipping incomplete batch\n",
      "loss: 0.23771495 acc: 0.8832532982973634\n",
      "Epoch 162\n",
      "skipping incomplete batch\n",
      "loss: 0.23529156 acc: 0.8851540585686895\n",
      "Epoch 163\n",
      "skipping incomplete batch\n",
      "loss: 0.23659751 acc: 0.886154458767512\n",
      "Epoch 164\n",
      "skipping incomplete batch\n",
      "loss: 0.24373573 acc: 0.881252497854997\n",
      "Epoch 165\n",
      "skipping incomplete batch\n",
      "loss: 0.24120112 acc: 0.8832532982347535\n",
      "Epoch 166\n",
      "skipping incomplete batch\n",
      "loss: 0.24410737 acc: 0.8824529781007394\n",
      "Epoch 167\n",
      "skipping incomplete batch\n",
      "loss: 0.2443009 acc: 0.8816526578862269\n",
      "Epoch 168\n",
      "skipping incomplete batch\n",
      "loss: 0.24537753 acc: 0.879951977634988\n",
      "Epoch 169\n",
      "skipping incomplete batch\n",
      "loss: 0.24734324 acc: 0.8814525779019169\n",
      "Epoch 170\n",
      "skipping incomplete batch\n",
      "loss: 0.2502699 acc: 0.8814525779287498\n",
      "Epoch 171\n",
      "skipping incomplete batch\n",
      "loss: 0.24357565 acc: 0.8831532582336542\n",
      "Epoch 172\n",
      "skipping incomplete batch\n",
      "loss: 0.2445476 acc: 0.8824529781365166\n",
      "Epoch 173\n",
      "skipping incomplete batch\n",
      "loss: 0.2449609 acc: 0.8794517775579375\n",
      "Epoch 174\n",
      "skipping incomplete batch\n",
      "loss: 0.2393847 acc: 0.883653458283872\n",
      "Epoch 175\n",
      "skipping incomplete batch\n",
      "loss: 0.23816437 acc: 0.8839535783676683\n",
      "Epoch 176\n",
      "skipping incomplete batch\n",
      "loss: 0.24186115 acc: 0.8822528979912097\n",
      "Epoch 177\n",
      "skipping incomplete batch\n",
      "loss: 0.23843323 acc: 0.8851540584971352\n",
      "Epoch 178\n",
      "skipping incomplete batch\n",
      "loss: 0.24040224 acc: 0.881752697914159\n",
      "Epoch 179\n",
      "skipping incomplete batch\n",
      "loss: 0.23672436 acc: 0.8853541385798323\n",
      "Epoch 180\n",
      "skipping incomplete batch\n",
      "loss: 0.2427562 acc: 0.8828531382035236\n",
      "Epoch 181\n",
      "skipping incomplete batch\n",
      "loss: 0.24559124 acc: 0.8792516975199618\n",
      "Epoch 182\n",
      "skipping incomplete batch\n",
      "loss: 0.24260558 acc: 0.8830532181073352\n",
      "Epoch 183\n",
      "skipping incomplete batch\n",
      "loss: 0.24308443 acc: 0.88085233778799\n",
      "Epoch 184\n",
      "skipping incomplete batch\n",
      "loss: 0.24143405 acc: 0.8820528179711226\n",
      "Epoch 185\n",
      "skipping incomplete batch\n",
      "loss: 0.25228086 acc: 0.87815125732004\n",
      "Epoch 186\n",
      "skipping incomplete batch\n",
      "loss: 0.2563874 acc: 0.8732492964343578\n",
      "Epoch 187\n",
      "skipping incomplete batch\n",
      "loss: 0.25917855 acc: 0.8724489762556223\n",
      "Epoch 188\n",
      "skipping incomplete batch\n",
      "loss: 0.25772974 acc: 0.8745498166454225\n",
      "Epoch 189\n",
      "skipping incomplete batch\n",
      "loss: 0.2915606 acc: 0.8613445342374163\n",
      "Epoch 190\n",
      "skipping incomplete batch\n",
      "loss: 0.2663546 acc: 0.8694477757575417\n",
      "Epoch 191\n",
      "skipping incomplete batch\n",
      "loss: 0.25602823 acc: 0.8740496165862605\n",
      "Epoch 192\n",
      "skipping incomplete batch\n",
      "loss: 0.26730832 acc: 0.87084833597865\n",
      "Epoch 193\n",
      "skipping incomplete batch\n",
      "loss: 0.2622565 acc: 0.8728491362600195\n",
      "Epoch 194\n",
      "skipping incomplete batch\n",
      "loss: 0.26176018 acc: 0.8738495364946192\n",
      "Epoch 195\n",
      "skipping incomplete batch\n",
      "loss: 0.25756723 acc: 0.8748499366755531\n",
      "Epoch 196\n",
      "skipping incomplete batch\n",
      "loss: 0.26445907 acc: 0.867246895321921\n",
      "Epoch 197\n",
      "skipping incomplete batch\n",
      "loss: 0.26320714 acc: 0.871248496045657\n",
      "Epoch 198\n",
      "skipping incomplete batch\n",
      "loss: 0.25831383 acc: 0.8745498166454225\n",
      "Epoch 199\n",
      "skipping incomplete batch\n",
      "loss: 0.2549295 acc: 0.8741496565694712\n",
      "Epoch 200\n",
      "skipping incomplete batch\n",
      "loss: 0.27456662 acc: 0.871248496045657\n",
      "Epoch 201\n",
      "skipping incomplete batch\n",
      "loss: 0.27544713 acc: 0.8714485760657441\n",
      "Epoch 202\n",
      "skipping incomplete batch\n",
      "loss: 0.25605467 acc: 0.8740496165952047\n",
      "Epoch 203\n",
      "skipping incomplete batch\n",
      "loss: 0.25537673 acc: 0.8756502568721771\n",
      "Epoch 204\n",
      "skipping incomplete batch\n",
      "loss: 0.25382406 acc: 0.8770508170843411\n",
      "Epoch 205\n",
      "skipping incomplete batch\n",
      "loss: 0.2529417 acc: 0.8794517775489932\n",
      "Epoch 206\n",
      "skipping incomplete batch\n",
      "loss: 0.2587855 acc: 0.8789515773735556\n",
      "Epoch 207\n",
      "skipping incomplete batch\n",
      "loss: 0.2572167 acc: 0.8775510171524473\n",
      "Epoch 208\n",
      "skipping incomplete batch\n",
      "loss: 0.25198507 acc: 0.8778511372272995\n",
      "Epoch 209\n",
      "skipping incomplete batch\n",
      "loss: 0.25004128 acc: 0.8792516974662962\n",
      "Epoch 210\n",
      "skipping incomplete batch\n",
      "loss: 0.24935175 acc: 0.8802520976561744\n",
      "Epoch 211\n",
      "skipping incomplete batch\n",
      "loss: 0.2635196 acc: 0.8747498966207882\n",
      "Epoch 212\n",
      "skipping incomplete batch\n",
      "loss: 0.26429695 acc: 0.8761504569045063\n",
      "Epoch 213\n",
      "skipping incomplete batch\n",
      "loss: 0.27358243 acc: 0.871248496045657\n",
      "Epoch 214\n",
      "skipping incomplete batch\n",
      "loss: 0.2687441 acc: 0.8734493764455007\n",
      "Epoch 215\n",
      "skipping incomplete batch\n",
      "loss: 0.2656435 acc: 0.8754501767626472\n",
      "Epoch 216\n",
      "skipping incomplete batch\n",
      "loss: 0.28123638 acc: 0.8616446542943798\n",
      "Epoch 217\n",
      "skipping incomplete batch\n",
      "loss: 0.2751716 acc: 0.869747895805561\n",
      "Epoch 218\n",
      "skipping incomplete batch\n",
      "loss: 0.2719891 acc: 0.8735494164644885\n",
      "Epoch 219\n",
      "skipping incomplete batch\n",
      "loss: 0.26731247 acc: 0.8746498567180759\n",
      "Epoch 220\n",
      "skipping incomplete batch\n",
      "loss: 0.2731972 acc: 0.8702480959094444\n",
      "Epoch 221\n",
      "skipping incomplete batch\n",
      "loss: 0.27186486 acc: 0.8728491361884653\n",
      "Epoch 222\n",
      "skipping incomplete batch\n",
      "loss: 0.2689156 acc: 0.8730492163158837\n",
      "Epoch 223\n",
      "skipping incomplete batch\n",
      "loss: 0.27287257 acc: 0.8719487761070176\n",
      "Epoch 224\n",
      "skipping incomplete batch\n",
      "loss: 0.2741607 acc: 0.8705482159037979\n",
      "Epoch 225\n",
      "skipping incomplete batch\n",
      "loss: 0.27105683 acc: 0.8711484560445577\n",
      "Epoch 226\n",
      "skipping incomplete batch\n",
      "loss: 0.27453697 acc: 0.8736494564387549\n",
      "Epoch 227\n",
      "skipping incomplete batch\n",
      "loss: 0.2718925 acc: 0.8696478557150189\n",
      "Epoch 228\n",
      "skipping incomplete batch\n",
      "loss: 0.2711706 acc: 0.8732492963270265\n",
      "Epoch 229\n",
      "skipping incomplete batch\n",
      "loss: 0.27995607 acc: 0.8686474555966949\n",
      "Epoch 230\n",
      "skipping incomplete batch\n",
      "loss: 0.28204256 acc: 0.8653461348985424\n",
      "Epoch 231\n",
      "skipping incomplete batch\n",
      "loss: 0.2873663 acc: 0.8640456147143105\n",
      "Epoch 232\n",
      "skipping incomplete batch\n",
      "loss: 0.28586638 acc: 0.8634453745377736\n",
      "Epoch 233\n",
      "skipping incomplete batch\n",
      "loss: 0.28294203 acc: 0.8633453345635071\n",
      "Epoch 234\n",
      "skipping incomplete batch\n",
      "loss: 0.29524538 acc: 0.8624449743836725\n",
      "Epoch 235\n",
      "skipping incomplete batch\n",
      "loss: 0.30087203 acc: 0.8585434138130884\n",
      "Epoch 236\n",
      "skipping incomplete batch\n",
      "loss: 0.29156977 acc: 0.8613445342463606\n",
      "Epoch 237\n",
      "skipping incomplete batch\n",
      "loss: 0.27813813 acc: 0.8709483759350278\n",
      "Epoch 238\n",
      "skipping incomplete batch\n",
      "loss: 0.29085085 acc: 0.8601440539916738\n",
      "Epoch 239\n",
      "skipping incomplete batch\n",
      "loss: 0.29417092 acc: 0.8554421732512986\n",
      "Epoch 240\n",
      "skipping incomplete batch\n",
      "loss: 0.28740445 acc: 0.8641456547601312\n",
      "Epoch 241\n",
      "skipping incomplete batch\n",
      "loss: 0.27959502 acc: 0.8670468153286667\n",
      "Epoch 242\n",
      "skipping incomplete batch\n",
      "loss: 0.27999124 acc: 0.8676470553710395\n",
      "Epoch 243\n",
      "skipping incomplete batch\n",
      "loss: 0.2793574 acc: 0.8678471354090151\n",
      "Epoch 244\n",
      "skipping incomplete batch\n",
      "loss: 0.27769116 acc: 0.8701480558367909\n",
      "Epoch 245\n",
      "skipping incomplete batch\n",
      "loss: 0.28181124 acc: 0.8675470154057173\n",
      "Epoch 246\n",
      "skipping incomplete batch\n",
      "loss: 0.2862432 acc: 0.8654461750248614\n",
      "Epoch 247\n",
      "skipping incomplete batch\n",
      "loss: 0.2780191 acc: 0.8697478957161182\n",
      "Epoch 248\n",
      "skipping incomplete batch\n",
      "loss: 0.27605906 acc: 0.8688475355094507\n",
      "Epoch 249\n",
      "skipping incomplete batch\n",
      "loss: 0.27683085 acc: 0.8702480958378902\n",
      "Epoch 250\n",
      "skipping incomplete batch\n",
      "loss: 0.2780982 acc: 0.8688475355273392\n",
      "Epoch 251\n",
      "skipping incomplete batch\n",
      "loss: 0.27866217 acc: 0.869447775730709\n",
      "Epoch 252\n",
      "skipping incomplete batch\n",
      "loss: 0.27610263 acc: 0.8711484559998364\n",
      "Epoch 253\n",
      "skipping incomplete batch\n",
      "loss: 0.27974477 acc: 0.8681472554659786\n",
      "Epoch 254\n",
      "skipping incomplete batch\n",
      "loss: 0.26709858 acc: 0.8762504969413827\n",
      "Epoch 255\n",
      "skipping incomplete batch\n",
      "loss: 0.28505427 acc: 0.8644457748975931\n",
      "Epoch 256\n",
      "skipping incomplete batch\n",
      "loss: 0.28380337 acc: 0.8648459348841017\n",
      "Epoch 257\n",
      "skipping incomplete batch\n",
      "loss: 0.28011212 acc: 0.8658463349755929\n",
      "Epoch 258\n",
      "skipping incomplete batch\n",
      "loss: 0.28100526 acc: 0.8681472554838672\n",
      "Epoch 259\n",
      "skipping incomplete batch\n",
      "loss: 0.28489807 acc: 0.8682472954939108\n",
      "Epoch 260\n",
      "skipping incomplete batch\n",
      "loss: 0.27608994 acc: 0.8668467352459697\n",
      "Epoch 261\n",
      "skipping incomplete batch\n",
      "loss: 0.2783446 acc: 0.8678471354716251\n",
      "Epoch 262\n",
      "skipping incomplete batch\n",
      "loss: 0.27302465 acc: 0.8681472554570343\n",
      "Epoch 263\n",
      "skipping incomplete batch\n",
      "loss: 0.27208024 acc: 0.8754501767984244\n",
      "Epoch 264\n",
      "skipping incomplete batch\n",
      "loss: 0.26754865 acc: 0.8754501768252572\n",
      "Epoch 265\n",
      "skipping incomplete batch\n",
      "loss: 0.2750755 acc: 0.871148456053502\n",
      "Epoch 266\n",
      "skipping incomplete batch\n",
      "loss: 0.28076425 acc: 0.8754501767715915\n",
      "Epoch 267\n",
      "skipping incomplete batch\n",
      "loss: 0.26737842 acc: 0.8771508571569946\n",
      "Epoch 268\n",
      "skipping incomplete batch\n",
      "loss: 0.26437828 acc: 0.8784513773143936\n",
      "Epoch 269\n",
      "skipping incomplete batch\n",
      "loss: 0.2664742 acc: 0.8775510171971688\n",
      "Epoch 270\n",
      "skipping incomplete batch\n",
      "loss: 0.2652201 acc: 0.8779511772910086\n",
      "Epoch 271\n",
      "skipping incomplete batch\n",
      "loss: 0.27872077 acc: 0.8676470554157608\n",
      "Epoch 272\n",
      "skipping incomplete batch\n",
      "loss: 0.27426112 acc: 0.871548616120509\n",
      "Epoch 273\n",
      "skipping incomplete batch\n",
      "loss: 0.26544878 acc: 0.8771508570675518\n",
      "Epoch 274\n",
      "skipping incomplete batch\n",
      "loss: 0.26309758 acc: 0.8796518575780246\n",
      "Epoch 275\n",
      "skipping incomplete batch\n",
      "loss: 0.26385623 acc: 0.8812524978371085\n",
      "Epoch 276\n",
      "skipping incomplete batch\n",
      "loss: 0.2690473 acc: 0.8826530580224395\n",
      "Epoch 277\n",
      "skipping incomplete batch\n",
      "loss: 0.26301903 acc: 0.8815526178135734\n",
      "Epoch 278\n",
      "skipping incomplete batch\n",
      "loss: 0.27591187 acc: 0.8725490163103873\n",
      "Epoch 279\n",
      "skipping incomplete batch\n",
      "loss: 0.3408272 acc: 0.8410364105886057\n",
      "Epoch 280\n",
      "skipping incomplete batch\n",
      "loss: 0.34157303 acc: 0.840236090436703\n",
      "Epoch 281\n",
      "skipping incomplete batch\n",
      "loss: 0.356308 acc: 0.8279311681638102\n",
      "Epoch 282\n",
      "skipping incomplete batch\n",
      "loss: 0.3359511 acc: 0.8393357302747568\n",
      "Epoch 283\n",
      "skipping incomplete batch\n",
      "loss: 0.33266833 acc: 0.839135650165227\n",
      "Epoch 284\n",
      "skipping incomplete batch\n",
      "loss: 0.3215891 acc: 0.8474389716964953\n",
      "Epoch 285\n",
      "skipping incomplete batch\n",
      "loss: 0.31408873 acc: 0.8522408925721339\n",
      "Epoch 286\n",
      "skipping incomplete batch\n",
      "loss: 0.31494892 acc: 0.8475390118317587\n",
      "Epoch 287\n",
      "skipping incomplete batch\n",
      "loss: 0.31324476 acc: 0.8482392918305094\n",
      "Epoch 288\n",
      "skipping incomplete batch\n",
      "loss: 0.309458 acc: 0.8537414928658956\n",
      "Epoch 289\n",
      "skipping incomplete batch\n",
      "loss: 0.31046766 acc: 0.8507402922962608\n",
      "Epoch 290\n",
      "skipping incomplete batch\n",
      "loss: 0.30822775 acc: 0.8532412928246221\n",
      "Epoch 291\n",
      "skipping incomplete batch\n",
      "loss: 0.3201011 acc: 0.8455382115235563\n",
      "Epoch 292\n",
      "skipping incomplete batch\n",
      "loss: 0.3036425 acc: 0.8547418930021082\n",
      "Epoch 293\n",
      "skipping incomplete batch\n",
      "loss: 0.29489636 acc: 0.8609443740899108\n",
      "Epoch 294\n",
      "skipping incomplete batch\n",
      "loss: 0.2894081 acc: 0.8625450144205489\n",
      "Epoch 295\n",
      "skipping incomplete batch\n",
      "loss: 0.31177655 acc: 0.8513405325085748\n",
      "Epoch 296\n",
      "skipping incomplete batch\n",
      "loss: 0.31073305 acc: 0.8526410526570295\n",
      "Epoch 297\n",
      "skipping incomplete batch\n",
      "loss: 0.3063722 acc: 0.854341732961934\n",
      "Epoch 298\n",
      "skipping incomplete batch\n",
      "loss: 0.30253878 acc: 0.8572428935036367\n",
      "Epoch 299\n",
      "skipping incomplete batch\n",
      "loss: 0.309852 acc: 0.8518407325319597\n",
      "Epoch 300\n",
      "skipping incomplete batch\n",
      "loss: 0.32462597 acc: 0.8428371309303865\n",
      "Epoch 301\n",
      "skipping incomplete batch\n",
      "loss: 0.3229333 acc: 0.8450380112318432\n",
      "Epoch 302\n",
      "skipping incomplete batch\n",
      "loss: 0.30852613 acc: 0.8533413328704428\n",
      "Epoch 303\n",
      "skipping incomplete batch\n",
      "loss: 0.3054286 acc: 0.8552420932848771\n",
      "Epoch 304\n",
      "skipping incomplete batch\n",
      "loss: 0.2975676 acc: 0.8573429335136803\n",
      "Epoch 305\n",
      "skipping incomplete batch\n",
      "loss: 0.30853894 acc: 0.8539415729664812\n",
      "Epoch 306\n",
      "skipping incomplete batch\n",
      "loss: 0.31723315 acc: 0.8505402122761737\n",
      "Epoch 307\n",
      "skipping incomplete batch\n",
      "loss: 0.3198223 acc: 0.8504401721856316\n",
      "Epoch 308\n",
      "skipping incomplete batch\n",
      "loss: 0.31632382 acc: 0.8502400922102659\n",
      "Epoch 309\n",
      "skipping incomplete batch\n",
      "loss: 0.31051737 acc: 0.849239691966722\n",
      "Epoch 310\n",
      "skipping incomplete batch\n",
      "loss: 0.31662393 acc: 0.8480392118730322\n",
      "Epoch 311\n",
      "skipping incomplete batch\n",
      "loss: 0.32512835 acc: 0.842737090920343\n",
      "Epoch 312\n",
      "skipping incomplete batch\n",
      "loss: 0.31329796 acc: 0.8466386516161468\n",
      "Epoch 313\n",
      "skipping incomplete batch\n",
      "loss: 0.3120883 acc: 0.8491396520908425\n",
      "Epoch 314\n",
      "skipping incomplete batch\n",
      "loss: 0.30758694 acc: 0.8542416929340019\n",
      "Epoch 315\n",
      "skipping incomplete batch\n",
      "loss: 0.30632293 acc: 0.8508403323152486\n",
      "Epoch 316\n",
      "skipping incomplete batch\n",
      "loss: 0.30988413 acc: 0.8478391317366695\n",
      "Epoch 317\n",
      "skipping incomplete batch\n",
      "loss: 0.3166276 acc: 0.8447378913627095\n",
      "Epoch 318\n",
      "skipping incomplete batch\n",
      "loss: 0.31497094 acc: 0.8450380113660073\n",
      "Epoch 319\n",
      "skipping incomplete batch\n",
      "loss: 0.32769695 acc: 0.8356342495543186\n",
      "Epoch 320\n",
      "skipping incomplete batch\n",
      "loss: 0.3164194 acc: 0.8410364105796614\n",
      "Epoch 321\n",
      "skipping incomplete batch\n",
      "loss: 0.306676 acc: 0.8511404524258778\n",
      "Epoch 322\n",
      "skipping incomplete batch\n",
      "loss: 0.29972404 acc: 0.8532412927172908\n",
      "Epoch 323\n",
      "skipping incomplete batch\n",
      "loss: 0.2970435 acc: 0.8538415328848834\n",
      "Epoch 324\n",
      "skipping incomplete batch\n",
      "loss: 0.32449687 acc: 0.845638251372603\n",
      "Epoch 325\n",
      "skipping incomplete batch\n",
      "loss: 0.33374438 acc: 0.8384353701306992\n",
      "Epoch 326\n",
      "skipping incomplete batch\n",
      "loss: 0.31827584 acc: 0.844237691160439\n",
      "Epoch 327\n",
      "skipping incomplete batch\n",
      "loss: 0.30545145 acc: 0.8567426933729205\n",
      "Epoch 328\n",
      "skipping incomplete batch\n",
      "loss: 0.30257368 acc: 0.8534413727552664\n",
      "Epoch 329\n",
      "skipping incomplete batch\n",
      "loss: 0.29581618 acc: 0.8554421732244658\n",
      "Epoch 330\n",
      "skipping incomplete batch\n",
      "loss: 0.29847616 acc: 0.8549419731116381\n",
      "Epoch 331\n",
      "skipping incomplete batch\n",
      "loss: 0.29581475 acc: 0.8549419730669167\n",
      "Epoch 332\n",
      "skipping incomplete batch\n",
      "loss: 0.29503515 acc: 0.8572428934857482\n",
      "Epoch 333\n",
      "skipping incomplete batch\n",
      "loss: 0.2960387 acc: 0.8533413327988886\n",
      "Epoch 334\n",
      "skipping incomplete batch\n",
      "loss: 0.294186 acc: 0.8571428533952061\n",
      "Epoch 335\n",
      "skipping incomplete batch\n",
      "loss: 0.292087 acc: 0.8593437338576597\n",
      "Epoch 336\n",
      "skipping incomplete batch\n",
      "loss: 0.29433507 acc: 0.8544417728735906\n",
      "Epoch 337\n",
      "skipping incomplete batch\n",
      "loss: 0.28959605 acc: 0.8581432536298058\n",
      "Epoch 338\n",
      "skipping incomplete batch\n",
      "loss: 0.29024696 acc: 0.8575430134711575\n",
      "Epoch 339\n",
      "skipping incomplete batch\n",
      "loss: 0.2887145 acc: 0.8595438138330255\n",
      "Epoch 340\n",
      "skipping incomplete batch\n",
      "loss: 0.2893773 acc: 0.8565426133438891\n",
      "Epoch 341\n",
      "skipping incomplete batch\n",
      "loss: 0.29020777 acc: 0.8577430935180774\n",
      "Epoch 342\n",
      "skipping incomplete batch\n",
      "loss: 0.28536814 acc: 0.8590436138006963\n",
      "Epoch 343\n",
      "skipping incomplete batch\n",
      "loss: 0.2826228 acc: 0.8604441740933586\n",
      "Epoch 344\n",
      "skipping incomplete batch\n",
      "loss: 0.28526813 acc: 0.8594437738677033\n",
      "Epoch 345\n",
      "skipping incomplete batch\n",
      "loss: 0.28225142 acc: 0.8604441739770831\n",
      "Epoch 346\n",
      "skipping incomplete batch\n",
      "loss: 0.2846132 acc: 0.8608443340262015\n",
      "Epoch 347\n",
      "skipping incomplete batch\n",
      "loss: 0.28365397 acc: 0.8625450143489947\n",
      "Epoch 348\n",
      "skipping incomplete batch\n",
      "loss: 0.28339273 acc: 0.8598439338542119\n",
      "Epoch 349\n",
      "skipping incomplete batch\n",
      "loss: 0.28068045 acc: 0.8605442140765693\n",
      "Epoch 350\n",
      "skipping incomplete batch\n",
      "loss: 0.28022045 acc: 0.8618447343412997\n",
      "Epoch 351\n",
      "skipping incomplete batch\n",
      "loss: 0.2779786 acc: 0.8646458547656276\n",
      "Epoch 352\n",
      "skipping incomplete batch\n",
      "loss: 0.2961691 acc: 0.8535414128189757\n",
      "Epoch 353\n",
      "skipping incomplete batch\n",
      "loss: 0.29603493 acc: 0.8499399721354138\n",
      "Epoch 354\n",
      "skipping incomplete batch\n",
      "loss: 0.29225266 acc: 0.8539415728233728\n",
      "Epoch 355\n",
      "skipping incomplete batch\n",
      "loss: 0.29026198 acc: 0.8566426533628769\n",
      "Epoch 356\n",
      "skipping incomplete batch\n",
      "loss: 0.29003817 acc: 0.8560424132310614\n",
      "Epoch 357\n",
      "skipping incomplete batch\n",
      "loss: 0.28587317 acc: 0.8581432536476944\n",
      "Epoch 358\n",
      "skipping incomplete batch\n",
      "loss: 0.29048133 acc: 0.8557422931472651\n",
      "Epoch 359\n",
      "skipping incomplete batch\n",
      "loss: 0.29447207 acc: 0.8559423732031294\n",
      "Epoch 360\n",
      "skipping incomplete batch\n",
      "loss: 0.29300544 acc: 0.8545418130356868\n",
      "Epoch 361\n",
      "skipping incomplete batch\n",
      "loss: 0.29362622 acc: 0.8560424132042286\n",
      "Epoch 362\n",
      "skipping incomplete batch\n",
      "loss: 0.28589544 acc: 0.8560424131773958\n",
      "Epoch 363\n",
      "skipping incomplete batch\n",
      "loss: 0.28870356 acc: 0.8552420930612703\n",
      "Epoch 364\n",
      "skipping incomplete batch\n",
      "loss: 0.2818474 acc: 0.8599439739179211\n",
      "Epoch 365\n",
      "skipping incomplete batch\n",
      "loss: 0.27818388 acc: 0.8617446942418134\n",
      "Epoch 366\n",
      "skipping incomplete batch\n",
      "loss: 0.27462828 acc: 0.8609443741077993\n",
      "Epoch 367\n",
      "skipping incomplete batch\n",
      "loss: 0.27452263 acc: 0.8594437738766476\n",
      "Epoch 368\n",
      "skipping incomplete batch\n",
      "loss: 0.2695092 acc: 0.8635454146551484\n",
      "Epoch 369\n",
      "skipping incomplete batch\n",
      "loss: 0.26765925 acc: 0.8648459347588818\n",
      "Epoch 370\n",
      "skipping incomplete batch\n",
      "loss: 0.26903498 acc: 0.8629451745054444\n",
      "Epoch 371\n",
      "skipping incomplete batch\n",
      "loss: 0.2688385 acc: 0.8639455746863784\n",
      "Epoch 372\n",
      "skipping incomplete batch\n",
      "loss: 0.2650482 acc: 0.8655462149186295\n",
      "Epoch 373\n",
      "skipping incomplete batch\n",
      "loss: 0.26443017 acc: 0.8684473754334994\n",
      "Epoch 374\n",
      "skipping incomplete batch\n",
      "loss: 0.26347944 acc: 0.866746695101762\n",
      "Epoch 375\n",
      "skipping incomplete batch\n",
      "loss: 0.26010743 acc: 0.8690476156189805\n",
      "Epoch 376\n",
      "skipping incomplete batch\n",
      "loss: 0.3109404 acc: 0.8543417330155997\n",
      "Epoch 377\n",
      "skipping incomplete batch\n",
      "loss: 0.30995044 acc: 0.848039211801478\n",
      "Epoch 378\n",
      "skipping incomplete batch\n",
      "loss: 0.30271822 acc: 0.8513405322402465\n",
      "Epoch 379\n",
      "skipping incomplete batch\n",
      "loss: 0.2992364 acc: 0.8532412926636251\n",
      "Epoch 380\n",
      "skipping incomplete batch\n",
      "loss: 0.30371228 acc: 0.8496398520426733\n",
      "Epoch 381\n",
      "skipping incomplete batch\n",
      "loss: 0.30277237 acc: 0.8501400522359994\n",
      "Epoch 382\n",
      "skipping incomplete batch\n",
      "loss: 0.29915243 acc: 0.85104041234428\n",
      "Epoch 383\n",
      "skipping incomplete batch\n",
      "loss: 0.29878923 acc: 0.8509403722447937\n",
      "Epoch 384\n",
      "skipping incomplete batch\n",
      "loss: 0.29606763 acc: 0.8538415328669948\n",
      "Epoch 385\n",
      "skipping incomplete batch\n",
      "loss: 0.29385522 acc: 0.8539415727697072\n",
      "Epoch 386\n",
      "skipping incomplete batch\n",
      "loss: 0.29644158 acc: 0.855742293111488\n",
      "Epoch 387\n",
      "skipping incomplete batch\n",
      "loss: 0.29528412 acc: 0.8551420531048923\n",
      "Epoch 388\n",
      "skipping incomplete batch\n",
      "loss: 0.27865705 acc: 0.860444174039693\n",
      "Epoch 389\n",
      "skipping incomplete batch\n",
      "loss: 0.27518672 acc: 0.8600440140263517\n",
      "Epoch 390\n",
      "skipping incomplete batch\n",
      "loss: 0.2926673 acc: 0.8518407324872384\n",
      "Epoch 391\n",
      "skipping incomplete batch\n",
      "loss: 0.2697388 acc: 0.862745094440636\n",
      "Epoch 392\n",
      "skipping incomplete batch\n",
      "loss: 0.27192104 acc: 0.8607442941771549\n",
      "Epoch 393\n",
      "skipping incomplete batch\n",
      "loss: 0.27087185 acc: 0.8617446943223118\n",
      "Epoch 394\n",
      "skipping incomplete batch\n",
      "loss: 0.26727375 acc: 0.8626450543411497\n",
      "Epoch 395\n",
      "skipping incomplete batch\n",
      "loss: 0.26384583 acc: 0.8650460147610805\n",
      "Epoch 396\n",
      "skipping incomplete batch\n",
      "loss: 0.29224372 acc: 0.8533413327183901\n",
      "Epoch 397\n",
      "skipping incomplete batch\n",
      "loss: 0.28398576 acc: 0.8534413727910436\n",
      "Epoch 398\n",
      "skipping incomplete batch\n",
      "loss: 0.27648073 acc: 0.8575430135069345\n",
      "Epoch 399\n",
      "skipping incomplete batch\n",
      "loss: 0.28569567 acc: 0.8517406924682505\n",
      "first batch:\n",
      "actual: [1.   1.   1.   1.   0.44 0.8 ]\n",
      "expected [True, True, True, True, False, True]\n",
      "new data:\n",
      "actual [1. 1. 1. 1. 1. 1.]\n",
      "expected [1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(model.loss)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch_num in range(400):\n",
    "        print(\"Epoch\", epoch_num)\n",
    "        losses = []\n",
    "        accs = []\n",
    "        for (batch_cnfs, batch_labels) in chunks((cnfs, labels), batch_size):\n",
    "            if len(batch_cnfs) < batch_size:\n",
    "                print(\"skipping incomplete batch\")\n",
    "                continue\n",
    "            inputs, lengths = pad_and_concat([cnf.clauses for cnf in batch_cnfs])\n",
    "            _, loss, probs = sess.run([train_op, model.loss, model.probabilities], feed_dict={\n",
    "                model.inputs: inputs,\n",
    "                model.labels: batch_labels,\n",
    "                model.lengths: lengths\n",
    "            })\n",
    "            losses.append(loss)\n",
    "            accs.append(1 - np.mean(np.abs(np.around(probs) - np.asarray(batch_labels))))\n",
    "            \n",
    "        print(\"loss:\", np.mean(np.asarray(losses)), \"acc:\", np.mean(accs))\n",
    "\n",
    "    print(\"first batch:\")\n",
    "    first_inputs, first_lengths = pad_and_concat([cnf.clauses for cnf in cnfs[:batch_size]])\n",
    "    probs = sess.run(model.probabilities, feed_dict={\n",
    "        model.inputs: first_inputs,\n",
    "        model.lengths: first_lengths\n",
    "    })\n",
    "    print(\"actual:\", probs)\n",
    "    print(\"expected\", labels[:batch_size])\n",
    "        \n",
    "    print(\"new data:\")\n",
    "    probs = sess.run(model.probabilities, feed_dict={\n",
    "        model.inputs: small_cnf,\n",
    "        model.lengths: small_lengths\n",
    "    })\n",
    "    print(\"actual\", probs)\n",
    "    print(\"expected\", small_sol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
